## Intro
This assignment is focused on reproducing a sentiment analysis from Chapter 2 in Text Mining with R by Julia Silge and David Robinson: https://www.tidytextmining.com/sentiment.html
The project is extended further by also analyzing the novel Les Miserables.

Loading libraries and sentiments
```{r}
library(janeaustenr)
library(dplyr)
library(stringr)
library(tidyr)
library(tidytext)
get_sentiments("afinn")
```
## Reproducing Project from Chapter 2 "Text Mining in R"
Tidy-ing the data within Jane Austen books.
Each row includes each word found in each of Austen's books, along with the 
chapter it is found in.
```{r}
tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
                         ignore_case=TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
tidy_books
#the arguments used in the unnest_tokens() funtion is relabeling the text column as "word"
```


Using the sentiment lexicon NRC, the sentiment "joy" was filtered from Austen's 
book "Emma", where each word associated with the emotion is filtered out and 
counted in its frequency throughout the book.
```{r}
#nrc
nrc_joy <- get_sentiments("nrc") %>%
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

```

In analyzing how sentiment changes across Austen's books, the Bing lexicon is 
used to analyze every 80 lines of each book in the data set.
```{r}
jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
#the count function is used to determine the amount of positive and negative sentiments per every 80 lines
    pivot_wider(names_from = sentiment, values_from = n, values_fill = 0 ) %>%
  mutate(sentiment = positive - negative)
jane_austen_sentiment 

```
Visualization of the changes in sentiment across each of Austen's books.
```{r}
library(ggplot2)
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol=2, scales = "free_x")
```
The following 3 chunks looks into how the sentiment of the novel "Pride and 
Prejudice" differs according to what lexicon is used.
```{r}
pride_prejudice <- tidy_books %>%
  filter(book == "Pride & Prejudice")
pride_prejudice
```

```{r}
afinn <- pride_prejudice %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(index = linenumber %/% 80) %>%
  summarise(sentiment = sum(value)) %>%
  mutate(method = "AFINN")
afinn

bing_and_nrc <- bind_rows(pride_prejudice %>% inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>%
    inner_join(get_sentiments("nrc") %>%
    filter(sentiment %in% c("positive", "negative"))) %>%
  mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, 
              values_from = n,
              values_fill = 0) %>%
  mutate(sentiment = positive - negative)
bing_and_nrc
```
```{r}
bind_rows(afinn, bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")

```

Looking into the positive and negative of both Bing and NRC
```{r}
get_sentiments("nrc") %>%
  filter(sentiment %in% c("positive", "negative")) %>%
    count(sentiment)

  get_sentiments("bing") %>%
  count(sentiment)
```

Retrieving the most frequently used sentimental words.
```{r}
bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
bing_word_counts
```
Visualizing the top 10 most frequently used negative and positive words use in 
"Pride and Prejudice".
```{r}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```

customizing stop words. The word "miss" is used in the novel to describe young,
unmarried women, not to long for someone/something.
```{r}
custom_stop_words <- 
  bind_rows(tibble(word = c("miss"),
                   lexicon = c("custom")),
            stop_words)

custom_stop_words

```

Creating a word cloud.
```{r}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```
comparing the most frequent positive and negative words
via word cloud.
```{r}
library(reshape2)

tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0)  %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

Working with sentences...
```{r}
p_and_p_sentences <- tibble(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")

p_and_p_sentences$sentence[2]
```
...and chapters
```{r}
austen_chapters <- austen_books() %>%
  group_by(book) %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())
```
Reviewing the chapters with containing the most 
negative sentimental words.
```{r}
bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")

wordcounts <- tidy_books %>%
  group_by(book, chapter) %>%
  summarize(words = n())

tidy_books %>%
  semi_join(bingnegative) %>%
  group_by(book, chapter) %>%
  summarize(negativewords = n()) %>%
  left_join(wordcounts, by = c("book", "chapter")) %>%
  mutate(ratio = negativewords/words) %>%
  filter(chapter != 0) %>%
  top_n(1) %>%
  ungroup()
```


## Analyzing Les Miserables
The rest of this assignment extends past the reproduced project to now including
a sentiment analysis of the novel Les Miserables

The gutenbergr package is used to retrieve the novel where it is then tidyd to a workable dataset.
```{r}
library(gutenbergr)

vhugo <- gutenberg_download(135)
les_mis <- vhugo %>%
  mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  select(-gutenberg_id)
les_mis 
```
Retrieving the sentiment score for each chapter
```{r}
les_mis_sentiment <- les_mis %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(chapter) %>%
  summarise(sentiment = sum(value))
les_mis_sentiment
```
Visualizing how the sentiment scores changes across the 365 chapters within Les Miserables
```{r}

  ggplot(les_mis_sentiment, aes(x = chapter, y = sentiment)) +
  geom_col() +
  labs(title = "Sentiment Analysis of Les MisÃ©rables",
       x = "Chapter ",
       y = "Sentiment Score") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```
The 10 most positive chapters based on their sentiment scores
```{r}
les_mis_sentiment %>%
  arrange(desc(sentiment)) %>% 
  head(10)
```
Analyzing the most positive words of the most positive chapter
```{r}
lesmis_pos_sentiment <- les_mis %>%
  filter(chapter == 351) %>%
  inner_join(get_sentiments("afinn")) %>%
  arrange(desc(value)) %>% 
  head(10)
lesmis_pos_sentiment 
```
Visualizing 
```{r}
lesmis_pos_sentiment_viz <- lesmis_pos_sentiment %>%
ggplot(aes(x = word, y = value)) +
  geom_col( fill= "#04D6D9") +
  labs(title = "Analysis of the 10 most Positive Words from the most Positive Chapter in Les Miserables",
       x = "Positive Words ",
       y = "Sentiment Score") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))  +
  coord_flip()
```


The 10 most negative chapters based on their sentiment scores
```{r}
les_mis_sentiment %>%
  arrange(desc(sentiment)) %>% 
  tail(10)
```
Analyzing the most positive words of the most positive chapter
```{r}
lesmis_neg_sentiment <- les_mis %>%
  filter(chapter == 220) %>%
  inner_join(get_sentiments("afinn")) %>%
  arrange(desc(value)) %>% 
  tail(10)
lesmis_neg_sentiment
```
Visualization
```{r}
lesmis_neg_sentiment_viz <- lesmis_neg_sentiment %>%
ggplot(aes(x = word, y = value)) +
  geom_col( fill= "#D92104") +
  labs(title = "Analysis of the 10 most Negative Words in the Most Negative Chapter in Les Miserables",
       x = "Negative Words ",
       y = "Sentiment Score") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_reverse()  +
  coord_flip()
```
```{r}
lesmis_pos_sentiment_viz
lesmis_neg_sentiment_viz
```



## Conclusion
The analysis of Les Miserables identifies the ten most positive and negative chapters of the novel.The 10 most positive words in the most positive chapter(351) suggest a theme of success and happiness while the 10 most negative words in the most negative chapter (220) suggests themes of oppression, suffering, and injustice.
